{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Convolutional Neural Network implementation example in Keras\n",
    "\n",
    "[Code for original example](https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the random seed, for reproducibility purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of elements processed in each training iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of possible classification classes (equal to the number of digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of full passes over the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little bit of housekeeping..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different Keras' backends assume different data representations. We are using Tensorflow, but, you know, best practices ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the tensors data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADTCAYAAACRDeixAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6tBFRDJCHbqISEaoQxcRyQh16CIiGfH/Gf2dGWWM2L0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9a36b4f710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for digit in range(num_classes): # for each digit\n",
    "    \n",
    "    # get the first example of the digit available\n",
    "    example_idx = np.where(y_train == digit)[0][0]\n",
    "    x_example = x_train[example_idx].reshape(img_rows, img_cols)\n",
    "    \n",
    "    # add it to the plot\n",
    "    ax = fig.add_subplot(2, 5, digit+1)\n",
    "    ax.imshow(x_example, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the valures from [0;255] to [0;1] range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train /= 255.\n",
    "x_test /= 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert class vectors to binary class matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply it also to testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of the training tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of samples for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of samples for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple, one-directional architecture layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the multiple layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(32,\n",
    "                 kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/nn1/relu.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://engineering.flipboard.com/assets/convnets/Convolution_schematic.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each convolutional layer has multiple filters in it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/53c160301db12a6e.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, \n",
    "                 kernel_size=(3, 3),\n",
    "                 activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what max-pooling does:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://shafeentejani.github.io/assets/images/pooling.gif'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model: set the loss and optimization definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 389s - loss: 0.3346 - acc: 0.8974 - val_loss: 0.0781 - val_acc: 0.9761\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.078140090218931438"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97609999999999997"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.\n",
    "\n",
    "Try running the model for more iterations (i.e. increase the 'epochs' variable to, e.g., 12). What do you detect? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2. (the hard one)\n",
    "\n",
    "Change the model definition (or create a new model) with the following layers configuration:\n",
    " * **2D Convolution**, with 32 filters and a 5x5 window, relu activation;\n",
    " * **Max-Polling**, with a factor of 2 horizontally and vertically;\n",
    " * **Dropout**, with probability of keeping the values of 0.7 (careful with this one ;) );\n",
    " * **2D Convolution**, with 64 filters and a 5x5 window, relu activation;\n",
    " * **Max-Polling**, with a factor of 2 horizontally and vertically;\n",
    " * **Dropout**, with probability of keeping the values of 0.7\n",
    " * **Flatten** the output, to prepare it for the fully-connected layer;\n",
    " * A **Dense** layer, with 1024 neurons;\n",
    " * An output **Dense** layer, with 10 neuros, activated with softmax.\n",
    "\n",
    "\n",
    "Does the result improve?\n",
    "\n",
    "\n",
    "(TIP: Go to [Keras documentation](https://keras.io/) to see the layers methods definition.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.\n",
    "\n",
    "Vary the dropout to 0, and compare the training accuracy in the test dataset. Can you gess what would happend if you set the dropout to 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4. (the hardest one)\n",
    "\n",
    "Can you come up with an architecture and configuration that improves on the previous results? Show it ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
